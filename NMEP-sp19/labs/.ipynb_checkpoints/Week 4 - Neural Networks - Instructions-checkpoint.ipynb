{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks + Cloud GPU Lab\n",
    "Today we'll be introducing how to use processing accelerators, called Graphics Processing Units (GPUs), to greatly speed up the training of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "In the olden days of machine learning, CPUs, like the Intel one that's probably in your laptop right now, were used to train neural networks. The problem was, these CPUs were too slow, and as a result it took weeks to train fairly small networks. If you've tried training a network on your laptop, you've probably experienced this.\n",
    "\n",
    "In recent years, however, the advent of Graphics Processing Units (GPUs) in deep learning has greatly accelerated network training speed by multiple orders of magnitude. GPUs are used for processing computer graphics in games, which so happens makes their design very useful for doing lots of linear algebra math! Nowadays a GPU can reduce the training time from weeks/months down to minutes, depending on the network and dataset used.\n",
    "\n",
    "### AWS and Google Colaboratory\n",
    "Buying your own GPU is of course, expensive, so big tech companies have made them available to rent (or use for free in the case of Google Colab) on the internet. Amazon Web Services (AWS), is the most popular provider of GPUs in the \"cloud\" (online rented compute power). They provide remote access to Linux machines in their datacenters, and we'll be going over how to use these to train models in the cloud. We'll also be going over how to use Google Colaboratory, which is a free service by Google that allows you to use Jupyter notebooks in your web browser in conjunction with (FREE!) GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colaboratory Introduction\n",
    "Google Colab is located at [Google's website](https://colab.research.google.com/notebooks/welcome.ipynb). In order to create a new notebook, you can either import an existing notebook or create your own. Today we'll be importing this notebook, so go ahead and upload this notebook using File -> Upload Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/mlberkeley/NMEP-sp19/blob/master/labs/week4/colab_upload.PNG?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see it looks just like a Jupyter notebook, but it's in Google! Now we're going to go ahead and enable GPU support. Click edit -> Notebook Settings -> change Hardware Accelerator to GPU. Now you have access to a (free!) K80 GPU for training purposes. Because Google offers this service for free, you'll be limited to 12 hours of contiguous use before your instance is killed, and your instance can be killed if Google runs low on resources. Also, you're limited to TensorFlow only (Keras accessible through `tf.keras`), so no PyTorch or custom code.\n",
    "\n",
    "You can now proceed to run whatever operations you want just like you would in a normal Jupyter notebook. For now though, we're going to pause to go over how to use a cloud GPU in AWS to train larger models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Web Services (AWS) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head to [AWS](https://aws.amazon.com/) and make an account if you don't already have one. This part will cost you a slight amount of money (<$1 depending on how long you take), so make sure you have a legitimate credit card linked to your AWS account.\n",
    "\n",
    "After you've created your account, go to the [Account Dashboard](https://us-west-2.console.aws.amazon.com/console/home?region=us-west-2#) and under the Services dropdown menu, click EC2. AWS EC2 is Amazon's name for its rentable online compute servers. Click the Launch Instance button to begin launching a new instance.\n",
    "\n",
    "![Launch Instance](https://github.com/mlberkeley/NMEP-sp19/blob/master/labs/week4/aws_ec2.PNG?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should then be presented with a list of Amazon Machine Images (AMIs). AMIs are the operating system that will be installed on your cloud machine. Scroll down until you find `Ubuntu 16.04 LTS` (make sure it's 16.04!), make sure the x86 option is checked, and click select.\n",
    "\n",
    "You should now be presented with the Choose an Instance Type page (below). AWS uses its own internal names to represent the type of machine you'll be renting (you can look up the details on AWS' pages), and we'll be using their cheapest GPU instance, the `p2.xlarge`. This instance contains 1 K80 GPU (~5 years old as of 2019) and should suffice for our purposes, although you may choose their newer and significantly faster instances for larger project work in the future.\n",
    "![Instance Type](https://github.com/mlberkeley/NMEP-sp19/blob/master/labs/week4/p2_xlarge.PNG?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and select the p2.xlarge instance and click Next. Make sure you don't click on Review and Launch!\n",
    "\n",
    "The next page, Configure Instance, can be skipped. The fourth step, Configure Storage, can be skipped for this tutorial, but you should add storage as necessary to accomodate whatever datasets you need for your projects. The Add Tags step can also be skipped.\n",
    "\n",
    "**The next step is very important!**\n",
    "\n",
    "On the Configure Security Group step, there should be only a single entry, SSH listed. Change the Source column of this row to \"Anywhere\". This will allow you to remotely access the machine from any IP address or computer as long as you have the machine's key.\n",
    "![Security Group](https://github.com/mlberkeley/NMEP-sp19/blob/master/labs/week4/security_group.PNG?raw=true)\n",
    "\n",
    "Now click Review, and click Launch. You will be presented with the dialog below asking you to create a private key. Give the private key a name and download your newly created key.\n",
    "![Private Key](https://github.com/mlberkeley/NMEP-sp19/blob/master/labs/week4/private_key.PNG?raw=true)\n",
    "\n",
    "**IT IS VERY IMPORTANT THAT YOU DO NOT 1) LOSE THIS FILE 2) UPLOAD IT TO ANY PUBLIC AREA (INCLUDING GIT/HUB!) DOING SO WILL EXPOSE ACCESS TO YOUR INSTANCE TO ANYONE WHO WANTS TO GET INTO IT!**\n",
    "\n",
    "The private key of your instance is the file that allows your computer (or anyone else who has the key) to connect to your cloud machine.\n",
    "\n",
    "Click Launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
